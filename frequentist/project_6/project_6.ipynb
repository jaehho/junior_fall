{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6: NMF\n",
    "\n",
    "Select a basic, explicit feedback dataset, many examples here:\n",
    "\n",
    "<https://gist.github.com/entaroadun/1653794>\n",
    "\n",
    "<https://github.com/caserec/Datasets-for-Recommender-Systems>\n",
    "\n",
    "<https://github.com/RUCAIBox/RecSysDatasets>\n",
    "\n",
    "And use the Surprise library:\n",
    "\n",
    "<http://surpriselib.com/>\n",
    "\n",
    "To implement a basic recommendation system. Many of those datasets are already loaded into the Surprise package to make this easy. You should tune and cross validate your system to select the best values for the # of latent dimensions, the regularization parameter, and any other hyperparameters.\n",
    "\n",
    "Stretch Goal #1 (3 points)\n",
    "\n",
    "Using an explicit feedback dataset, implement the NMF algorithm by hand, tune it via cross validation to select the # of latent dims and regularization parameter\n",
    "\n",
    "Stretch goal #2 (3 points)\n",
    "\n",
    "Using an implicit feedback dataset, some can be found here:\n",
    "\n",
    "<https://cseweb.ucsd.edu/~jmcauley/datasets.html>\n",
    "\n",
    "And implement the implicit feedback version of NMF. Evaluating performance will be harder however, so instead of doing a grid search and tuning, try to output the ratings explanations (i.e. use eqn 7 of the implicit feedback dataset).  Nobody has ever attempted this stretch goal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NMF, Dataset, accuracy\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('196', '242', 3.0, '881250949'),\n",
       " ('186', '302', 3.0, '891717742'),\n",
       " ('22', '377', 1.0, '878887116'),\n",
       " ('244', '51', 2.0, '880606923'),\n",
       " ('166', '346', 1.0, '886397596')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the MovieLens 100k dataset\n",
    "data = Dataset.load_builtin('ml-100k', prompt=False)\n",
    "data.raw_ratings[:5] # columns: user_id, item_id, rating, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_factors': 10, 'n_epochs': 30, 'reg_pu': 0.2, 'reg_qi': 0.01, 'biased': True}\n",
      "Best RMSE: 0.9369756933233495\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters with GridSearchCV class from Surprise\n",
    "param_grid = {\n",
    "    'n_factors': list(range(10, 60, 10)), # Number of latent factors\n",
    "    'n_epochs': list(range(10, 40, 10)), # Number of epochs\n",
    "    'reg_pu': np.linspace(0.01, 0.2, 5).tolist(), # Regularization for user factors\n",
    "    'reg_qi': np.linspace(0.01, 0.2, 5).tolist(), # Regularization for item factors\n",
    "    'biased': [True, False] # Include user/item bias terms\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(NMF, param_grid, measures=['rmse'], cv=5, n_jobs=-1) # cv=5 is 5-fold cross-validation\n",
    "gs.fit(data)\n",
    "best_params = gs.best_params['rmse']\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best RMSE:\", gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9370796130578684\n"
     ]
    }
   ],
   "source": [
    "# Train the system\n",
    "test_size = 0.2\n",
    "trainset, testset = train_test_split(data, test_size=test_size)\n",
    "algo = NMF(**best_params)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "rmse = accuracy.rmse(predictions, verbose=False)\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations for user 196: ['1554', '1467', '1358', '1631', '1449']\n"
     ]
    }
   ],
   "source": [
    "# Recommend items for a specific user\n",
    "user_id = '196'  # MovieLens user ID\n",
    "\n",
    "all_items = set(iid for (_, iid, _, _) in data.raw_ratings)\n",
    "rated_items = set(iid for (uid, iid, _, _) in data.raw_ratings if uid == str(user_id))\n",
    "unrated_items = list(all_items - rated_items)\n",
    "predictions = [(item, algo.predict(str(user_id), item).est) for item in unrated_items]\n",
    "recommendations = sorted(predictions, key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "print(f\"Top recommendations for user {user_id}:\", [item for item, _ in recommendations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_rmse(data, user_id):\n",
    "    \"\"\"\n",
    "    Calculate RMSE for the naive recommendation system.\n",
    "    \"\"\"\n",
    "    # Compute global average for all items\n",
    "    global_average = np.mean([float(rating) for (_, _, rating, _) in data.raw_ratings])\n",
    "\n",
    "    # Get test ratings for the user\n",
    "    test_ratings = [(uid, iid, float(rating)) for (uid, iid, rating, _) in data.raw_ratings if uid == str(user_id)]\n",
    "\n",
    "    # Calculate RMSE for naive predictions\n",
    "    errors = [(rating - global_average) ** 2 for (_, _, rating) in test_ratings]\n",
    "    rmse = np.sqrt(np.mean(errors))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (Surprise): 0.9370796130578684\n",
      "Test RMSE (Naive): 1.0065940689274897\n"
     ]
    }
   ],
   "source": [
    "naive_rmse_score = naive_rmse(data, user_id)\n",
    "\n",
    "print(\"Test RMSE (Surprise):\", rmse)\n",
    "print(\"Test RMSE (Naive):\", naive_rmse_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goal 1: NMF by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating  timestamp\n",
       "0          196      242       3  881250949\n",
       "1          186      302       3  891717742\n",
       "2           22      377       1  878887116\n",
       "3          244       51       2  880606923\n",
       "4          166      346       1  886397596\n",
       "...        ...      ...     ...        ...\n",
       "99995      880      476       3  880175444\n",
       "99996      716      204       5  879795543\n",
       "99997      276     1090       1  874795795\n",
       "99998       13      225       2  882399156\n",
       "99999       12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the MovieLens 100k dataset\n",
    "url = \"http://files.grouplens.org/datasets/movielens/ml-100k/u.data\"\n",
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "data = pd.read_csv(url, sep='\\t', names=column_names)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 4, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 5, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['timestamp'])\n",
    "\n",
    "# Adjust user_id and item_id to start from 0 (zero-indexed)\n",
    "data['user_id'] -= 1\n",
    "data['item_id'] -= 1\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a sparse matrix for faster computations (reference: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)\n",
    "n_users = data['user_id'].max() + 1\n",
    "n_items = data['item_id'].max() + 1\n",
    "train_matrix = csr_matrix(\n",
    "    (train_data['rating'], (train_data['user_id'], train_data['item_id'])),\n",
    "    shape=(n_users, n_items)\n",
    ")\n",
    "train_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train matrix\n",
      "[[0 3 4 ... 0 0 0]\n",
      " [4 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [5 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 0]]\n",
      "predicted matrix\n",
      "[[0.         2.99949834 3.99900161 ... 0.         0.         2.90625753]\n",
      " [0.         2.90628561 3.87472821 ... 0.         0.         2.81594236]\n",
      " [0.         2.40898983 3.2117218  ... 0.         0.         2.33410525]\n",
      " ...\n",
      " [0.         2.75123703 3.66801381 ... 0.         0.         2.66571354]\n",
      " [0.         3.11214712 4.14918761 ... 0.         0.         3.01540457]\n",
      " [0.         2.8554442  3.80694525 ... 0.         0.         2.76668138]]\n"
     ]
    }
   ],
   "source": [
    "def als_reconstruct(sparse_matrix, n_factors=10, iterations=10, reg=0.1):\n",
    "    \"\"\"\n",
    "    Alternating Least Squares for matrix reconstruction.\n",
    "    \n",
    "    Parameters:\n",
    "    - sparse_matrix: The user-item matrix (CSR format).\n",
    "    - n_factors: Number of latent factors.\n",
    "    - iterations: Number of ALS iterations.\n",
    "    - reg: Regularization term.\n",
    "    \n",
    "    Returns:\n",
    "    - reconstructed_matrix: The predicted user-item matrix.\n",
    "    \"\"\"\n",
    "    n_users, n_items = sparse_matrix.shape\n",
    "    user_factors = np.random.rand(n_users, n_factors)\n",
    "    item_factors = np.random.rand(n_items, n_factors)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Fix item factors and update user factors\n",
    "        for u in range(n_users):\n",
    "            non_zero = sparse_matrix[u].indices\n",
    "            if len(non_zero) > 0:\n",
    "                A = item_factors[non_zero].T @ item_factors[non_zero] + reg * np.eye(n_factors)\n",
    "                b = sparse_matrix[u, non_zero].toarray().flatten() @ item_factors[non_zero]\n",
    "                user_factors[u] = np.linalg.solve(A, b)\n",
    "        \n",
    "        # Fix user factors and update item factors\n",
    "        for i in range(n_items):\n",
    "            non_zero = sparse_matrix[:, i].indices\n",
    "            if len(non_zero) > 0:\n",
    "                A = user_factors[non_zero].T @ user_factors[non_zero] + reg * np.eye(n_factors)\n",
    "                b = sparse_matrix[non_zero, i].toarray().flatten() @ user_factors[non_zero]\n",
    "                item_factors[i] = np.linalg.solve(A, b)\n",
    "    \n",
    "    return user_factors @ item_factors.T\n",
    "\n",
    "predicted_matrix = als_reconstruct(train_matrix, n_factors=10, iterations=10, reg=0.1)\n",
    "print(\"train matrix\")\n",
    "print(train_matrix.toarray())\n",
    "print(\"predicted matrix\")\n",
    "print(predicted_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.0639695078899045\n"
     ]
    }
   ],
   "source": [
    "def calculate_rmse(test_data, predicted_matrix):\n",
    "    errors = []\n",
    "    for _, row in test_data.iterrows():\n",
    "        user, item, actual = int(row['user_id']), int(row['item_id']), row['rating']\n",
    "        predicted = predicted_matrix[user, item]\n",
    "        errors.append((actual - predicted) ** 2)\n",
    "    return np.sqrt(np.mean(errors))\n",
    "\n",
    "rmse = calculate_rmse(test_data, predicted_matrix)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'n_factors': 10, 'reg': 0.01, 'iterations': 5}\n",
      "Average RMSE: 3.05089057074541\n",
      "Testing parameters: {'n_factors': 10, 'reg': 0.01, 'iterations': 50}\n",
      "Average RMSE: 3.05092776527504\n",
      "Testing parameters: {'n_factors': 10, 'reg': 0.1, 'iterations': 5}\n",
      "Average RMSE: 3.0492360015130227\n",
      "Testing parameters: {'n_factors': 10, 'reg': 0.1, 'iterations': 50}\n",
      "Average RMSE: 3.0491201992159365\n",
      "Testing parameters: {'n_factors': 50, 'reg': 0.01, 'iterations': 5}\n",
      "Average RMSE: 3.0508511312388853\n",
      "Testing parameters: {'n_factors': 50, 'reg': 0.01, 'iterations': 50}\n",
      "Average RMSE: 3.050918820576931\n",
      "Testing parameters: {'n_factors': 50, 'reg': 0.1, 'iterations': 5}\n",
      "Average RMSE: 3.048963074454243\n",
      "Testing parameters: {'n_factors': 50, 'reg': 0.1, 'iterations': 50}\n",
      "Average RMSE: 3.0489864929846604\n",
      "Best Parameters: {'n_factors': 50, 'reg': 0.1, 'iterations': 5}\n",
      "Best RMSE: 3.048963074454243\n"
     ]
    }
   ],
   "source": [
    "def cross_validate_als(data, param_comb, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    rmse_list = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(data):\n",
    "        train_data = data.iloc[train_index]\n",
    "        val_data = data.iloc[val_index]\n",
    "        \n",
    "        train_matrix = csr_matrix(\n",
    "            (train_data['rating'], (train_data['user_id'], train_data['item_id'])),\n",
    "            shape=(n_users, n_items)\n",
    "        )\n",
    "        \n",
    "        predicted_matrix = als_reconstruct(\n",
    "            train_matrix,\n",
    "            n_factors=param_comb['n_factors'],\n",
    "            iterations=param_comb['iterations'],\n",
    "            reg=param_comb['reg']\n",
    "        )\n",
    "        \n",
    "        rmse = calculate_rmse(val_data, predicted_matrix)\n",
    "        rmse_list.append(rmse)\n",
    "    \n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "# Define grid search parameters\n",
    "param_grid = {\n",
    "    'n_factors': [10, 50],\n",
    "    'reg': [0.01, 0.1],\n",
    "    'iterations': [5, 50]\n",
    "}\n",
    "\n",
    "best_params = None\n",
    "best_rmse = float('inf')\n",
    "# Iterate over all parameter combinations\n",
    "for comb in itertools.product(*param_grid.values()):\n",
    "    param_comb = dict(zip(param_grid.keys(), comb))\n",
    "    print(f\"Testing parameters: {param_comb}\")\n",
    "    \n",
    "    avg_rmse = cross_validate_als(data, param_comb)\n",
    "    print(f\"Average RMSE: {avg_rmse}\")\n",
    "    \n",
    "    if avg_rmse < best_rmse:\n",
    "        best_rmse = avg_rmse\n",
    "        best_params = param_comb\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best RMSE: {best_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
